<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dvt.video API documentation</title>
<meta name="description" content="Video files." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:20%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
<link rel="canonical" href="https://pdoc3.github.io/pdoc/doc/dvt/video.html">
<link rel="icon" href="https://pdoc3.github.io/pdoc/logo.png">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dvt.video</code></h1>
</header>
<section id="section-intro">
<p>Video files.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;Video files.
&#34;&#34;&#34;

from math import ceil
from numpy import zeros, uint8
from pandas import DataFrame
from cv2 import (
    VideoCapture,
    CAP_PROP_FPS,
    CAP_PROP_FRAME_COUNT,
    CAP_PROP_FRAME_HEIGHT,
    CAP_PROP_FRAME_WIDTH,
    CAP_PROP_POS_MSEC,
)

from .utils import _expand_path


class VideoFrameInput:
    &#34;&#34;&#34;An input object for extracting single frames from an input video.&#34;&#34;&#34;

    def __init__(self, input_path):
        &#34;&#34;&#34;Construct a new input from a video file.

        Args:
            input_path (str): Path to the video file. Can be any file readable
                by the OpenCV function VideoCapture.
            bsize (int): Number of frames to include in a batch. Defaults to
                256.
        &#34;&#34;&#34;
        self.input_path = _expand_path(input_path)[0]
        self.meta = None
        self.fcount = -1
        self.finished = False
        self._video_cap = None
        self.reset()

        super().__init__()

    def reset(self):
        &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
        self.fcount = -1
        self.finished = False

        self._video_cap = VideoCapture(self.input_path)
        self._ftotal = int(self._video_cap.get(CAP_PROP_FRAME_COUNT))
        self.meta = self._metadata()

    def next_frame(self):
        &#34;&#34;&#34;Get the next frame.&#34;&#34;&#34;
        if self.finished:
            return

        # get the next frame and return
        self.fcount = self.fcount + 1
        _, frame = self._video_cap.read()
        self.finished = self._ftotal == (self.fcount + 1)
        return frame

    def get_metadata(self):
        &#34;&#34;&#34;Return metadata in a format to put into DVTOutput&#34;&#34;&#34;
        return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}

    def _metadata(self):
        &#34;&#34;&#34;Fill metadata attribute using metadata from the video source.&#34;&#34;&#34;
        path, bname, filename, file_extension = _expand_path(self.input_path)
        return {
            &#34;type&#34;: &#34;video&#34;,
            &#34;fps&#34;: self._video_cap.get(CAP_PROP_FPS),
            &#34;frames&#34;: int(self._video_cap.get(CAP_PROP_FRAME_COUNT)),
            &#34;height&#34;: int(self._video_cap.get(CAP_PROP_FRAME_HEIGHT)),
            &#34;width&#34;: int(self._video_cap.get(CAP_PROP_FRAME_WIDTH)),
            &#34;input_path&#34;: path,
            &#34;input_bname&#34;: bname,
            &#34;input_filename&#34;: filename,
            &#34;input_file_extension&#34;: file_extension,
        }


class VideoBatchInput:
    &#34;&#34;&#34;An input object for extracting batches of images from an input video.&#34;&#34;&#34;

    def __init__(self, input_path, bsize=256):
        &#34;&#34;&#34;Construct a new input from a video file.

        Args:
            input_path (str): Path to the video file. Can be any file readable
                by the OpenCV function VideoCapture.
            bsize (int): Number of frames to include in a batch. Defaults to
                256.
        &#34;&#34;&#34;
        self.input_path = _expand_path(input_path)[0]
        self.bsize = bsize
        self.meta = None
        self.fcount = 0
        self.finished = False
        self.start = 0
        self.end = 0
        self.max_batch = 0
        self._video_cap = None
        self._img = None
        self._continue_read = True
        self.reset()

        super().__init__()

    def reset(self):
        &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
        # start settings to
        self.fcount = 0
        self.finished = False
        self.start = 0
        self.end = 0
        self._video_cap = VideoCapture(self.input_path)
        self.meta = self._metadata()
        self.max_batch = ceil(self.meta[&#34;frames&#34;] / self.bsize)

        self._img = zeros(
            (self.bsize * 2, self.meta[&#34;height&#34;], self.meta[&#34;width&#34;], 3),
            dtype=uint8,
        )
        self._fill_bandwidth()  # fill the buffer with the first batch
        self._continue_read = True  # is there any more input left

    def next_batch(self):
        &#34;&#34;&#34;Move forward one batch and return the current FrameBatch object.

        Returns:
            A FrameBatch object that contains the next set of frames.
        &#34;&#34;&#34;

        if self.finished:
            return

        # shift window over by one bandwidth
        self._img[: self.bsize, :, :, :] = self._img[self.bsize :, :, :, :]

        # fill up the bandwidth; with zeros at and of video input
        if self._continue_read:
            self._fill_bandwidth()
        else:
            self.finished = True
            self._img[self.bsize :, :, :, :] = 0

        # update counters
        frame_start = self.fcount
        self.start = self.end
        self.end = self._video_cap.get(CAP_PROP_POS_MSEC)
        self.fcount = self.fcount + self.bsize

        # get frame names
        fnames = list(range(int(frame_start), int(frame_start + self.bsize)))

        # return batch of frames.
        return FrameBatch(
            img=self._img,
            start=self.start,
            end=self.end,
            finished=self.finished,
            fnames=fnames,
            bnum=(frame_start // self.bsize),
        )

    def get_metadata(self):
        &#34;&#34;&#34;Return metadata in a format to put into a DVTOutput object.&#34;&#34;&#34;
        return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}

    def _metadata(self):
        &#34;&#34;&#34;Fill metadata attribute using metadata from the video source.&#34;&#34;&#34;
        path, bname, filename, file_extension = _expand_path(self.input_path)
        return {
            &#34;type&#34;: &#34;video&#34;,
            &#34;fps&#34;: self._video_cap.get(CAP_PROP_FPS),
            &#34;frames&#34;: int(self._video_cap.get(CAP_PROP_FRAME_COUNT)),
            &#34;height&#34;: int(self._video_cap.get(CAP_PROP_FRAME_HEIGHT)),
            &#34;width&#34;: int(self._video_cap.get(CAP_PROP_FRAME_WIDTH)),
            &#34;input_path&#34;: path,
            &#34;input_bname&#34;: bname,
            &#34;input_filename&#34;: filename,
            &#34;input_file_extension&#34;: file_extension,
        }

    def _fill_bandwidth(self):
        &#34;&#34;&#34;Read in the next set of frames from disk and store results.

        This should not be called directly, but only through the next_batch
        method. Otherwise the internal counters will become inconsistent.
        &#34;&#34;&#34;
        for idx in range(self.bsize):
            self._continue_read, frame = self._video_cap.read()
            if self._continue_read:
                self._img[idx + self.bsize, :, :, :] = frame
            else:
                self._img[idx + self.bsize, :, :, :] = 0


class FrameBatch:
    &#34;&#34;&#34;A collection of frames and associated metadata.

    The batch contains an array of size (bsize * 2, width, height, 3). At the
    start and end of the video file, the array is padded with zeros (an all
    black frame). The batch includes twice as many frames as given in the
    batch size, but an annotator should only return results from the first
    half of the data (the &#34;batch&#34;). The other data is included for annotators
    that need to look ahead of the current, such as the cut detectors.

    Attributes:
        img (np.array): A four-dimensional array containing pixels from the
            next 2*bsize of images.
        start (float): Time code at the start of the current batch.
        end (float): Time code at the end of the current batch.
        fnames (list): Names of frames in the batch.
        bnum (int): The batch number.
        bsize (int): Number of frames in a batch.
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.img = kwargs.get(&#34;img&#34;)
        self.start = kwargs.get(&#34;start&#34;)
        self.end = kwargs.get(&#34;end&#34;)
        self.fnames = kwargs.get(&#34;fnames&#34;)
        self.bnum = kwargs.get(&#34;bnum&#34;)
        self.bsize = self.img.shape[0] // 2

    def get_frames(self):
        &#34;&#34;&#34;Return the entire image dataset for the batch.

        Use this method if you need to look ahead at the following batch for
        an annotator to work. Images are given in RGB space.

        Returns:
            A four-dimensional array containing pixels from the current and
            next batches of data.
        &#34;&#34;&#34;
        return self.img

    def get_batch(self):
        &#34;&#34;&#34;Return image data for just the current batch.

        Use this method unless you have a specific need to look ahead at new
        values in the data. Images are given in RGB space.

        Returns:
            A four-dimensional array containing pixels from the current batch
            of images.
        &#34;&#34;&#34;
        return self.img[: self.bsize, :, :, :]

    def get_frame_names(self):
        &#34;&#34;&#34;Return frame names for the current batch of data.

        Returns:
            A list of names of length equal to the batch size.
        &#34;&#34;&#34;
        return self.fnames</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dvt.video.FrameBatch"><code class="flex name class">
<span>class <span class="ident">FrameBatch</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A collection of frames and associated metadata.</p>
<p>The batch contains an array of size (bsize * 2, width, height, 3). At the
start and end of the video file, the array is padded with zeros (an all
black frame). The batch includes twice as many frames as given in the
batch size, but an annotator should only return results from the first
half of the data (the "batch"). The other data is included for annotators
that need to look ahead of the current, such as the cut detectors.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>img</code></strong> :&ensp;<code>np.array</code></dt>
<dd>A four-dimensional array containing pixels from the
next 2*bsize of images.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code></dt>
<dd>Time code at the start of the current batch.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code></dt>
<dd>Time code at the end of the current batch.</dd>
<dt><strong><code>fnames</code></strong> :&ensp;<code>list</code></dt>
<dd>Names of frames in the batch.</dd>
<dt><strong><code>bnum</code></strong> :&ensp;<code>int</code></dt>
<dd>The batch number.</dd>
<dt><strong><code>bsize</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of frames in a batch.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FrameBatch:
    &#34;&#34;&#34;A collection of frames and associated metadata.

    The batch contains an array of size (bsize * 2, width, height, 3). At the
    start and end of the video file, the array is padded with zeros (an all
    black frame). The batch includes twice as many frames as given in the
    batch size, but an annotator should only return results from the first
    half of the data (the &#34;batch&#34;). The other data is included for annotators
    that need to look ahead of the current, such as the cut detectors.

    Attributes:
        img (np.array): A four-dimensional array containing pixels from the
            next 2*bsize of images.
        start (float): Time code at the start of the current batch.
        end (float): Time code at the end of the current batch.
        fnames (list): Names of frames in the batch.
        bnum (int): The batch number.
        bsize (int): Number of frames in a batch.
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.img = kwargs.get(&#34;img&#34;)
        self.start = kwargs.get(&#34;start&#34;)
        self.end = kwargs.get(&#34;end&#34;)
        self.fnames = kwargs.get(&#34;fnames&#34;)
        self.bnum = kwargs.get(&#34;bnum&#34;)
        self.bsize = self.img.shape[0] // 2

    def get_frames(self):
        &#34;&#34;&#34;Return the entire image dataset for the batch.

        Use this method if you need to look ahead at the following batch for
        an annotator to work. Images are given in RGB space.

        Returns:
            A four-dimensional array containing pixels from the current and
            next batches of data.
        &#34;&#34;&#34;
        return self.img

    def get_batch(self):
        &#34;&#34;&#34;Return image data for just the current batch.

        Use this method unless you have a specific need to look ahead at new
        values in the data. Images are given in RGB space.

        Returns:
            A four-dimensional array containing pixels from the current batch
            of images.
        &#34;&#34;&#34;
        return self.img[: self.bsize, :, :, :]

    def get_frame_names(self):
        &#34;&#34;&#34;Return frame names for the current batch of data.

        Returns:
            A list of names of length equal to the batch size.
        &#34;&#34;&#34;
        return self.fnames</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dvt.video.FrameBatch.get_batch"><code class="name flex">
<span>def <span class="ident">get_batch</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return image data for just the current batch.</p>
<p>Use this method unless you have a specific need to look ahead at new
values in the data. Images are given in RGB space.</p>
<h2 id="returns">Returns</h2>
<p>A four-dimensional array containing pixels from the current batch
of images.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_batch(self):
    &#34;&#34;&#34;Return image data for just the current batch.

    Use this method unless you have a specific need to look ahead at new
    values in the data. Images are given in RGB space.

    Returns:
        A four-dimensional array containing pixels from the current batch
        of images.
    &#34;&#34;&#34;
    return self.img[: self.bsize, :, :, :]</code></pre>
</details>
</dd>
<dt id="dvt.video.FrameBatch.get_frame_names"><code class="name flex">
<span>def <span class="ident">get_frame_names</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return frame names for the current batch of data.</p>
<h2 id="returns">Returns</h2>
<p>A list of names of length equal to the batch size.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_frame_names(self):
    &#34;&#34;&#34;Return frame names for the current batch of data.

    Returns:
        A list of names of length equal to the batch size.
    &#34;&#34;&#34;
    return self.fnames</code></pre>
</details>
</dd>
<dt id="dvt.video.FrameBatch.get_frames"><code class="name flex">
<span>def <span class="ident">get_frames</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the entire image dataset for the batch.</p>
<p>Use this method if you need to look ahead at the following batch for
an annotator to work. Images are given in RGB space.</p>
<h2 id="returns">Returns</h2>
<p>A four-dimensional array containing pixels from the current and
next batches of data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_frames(self):
    &#34;&#34;&#34;Return the entire image dataset for the batch.

    Use this method if you need to look ahead at the following batch for
    an annotator to work. Images are given in RGB space.

    Returns:
        A four-dimensional array containing pixels from the current and
        next batches of data.
    &#34;&#34;&#34;
    return self.img</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dvt.video.VideoBatchInput"><code class="flex name class">
<span>class <span class="ident">VideoBatchInput</span></span>
<span>(</span><span>input_path, bsize=256)</span>
</code></dt>
<dd>
<div class="desc"><p>An input object for extracting batches of images from an input video.</p>
<p>Construct a new input from a video file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the video file. Can be any file readable
by the OpenCV function VideoCapture.</dd>
<dt><strong><code>bsize</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of frames to include in a batch. Defaults to
256.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VideoBatchInput:
    &#34;&#34;&#34;An input object for extracting batches of images from an input video.&#34;&#34;&#34;

    def __init__(self, input_path, bsize=256):
        &#34;&#34;&#34;Construct a new input from a video file.

        Args:
            input_path (str): Path to the video file. Can be any file readable
                by the OpenCV function VideoCapture.
            bsize (int): Number of frames to include in a batch. Defaults to
                256.
        &#34;&#34;&#34;
        self.input_path = _expand_path(input_path)[0]
        self.bsize = bsize
        self.meta = None
        self.fcount = 0
        self.finished = False
        self.start = 0
        self.end = 0
        self.max_batch = 0
        self._video_cap = None
        self._img = None
        self._continue_read = True
        self.reset()

        super().__init__()

    def reset(self):
        &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
        # start settings to
        self.fcount = 0
        self.finished = False
        self.start = 0
        self.end = 0
        self._video_cap = VideoCapture(self.input_path)
        self.meta = self._metadata()
        self.max_batch = ceil(self.meta[&#34;frames&#34;] / self.bsize)

        self._img = zeros(
            (self.bsize * 2, self.meta[&#34;height&#34;], self.meta[&#34;width&#34;], 3),
            dtype=uint8,
        )
        self._fill_bandwidth()  # fill the buffer with the first batch
        self._continue_read = True  # is there any more input left

    def next_batch(self):
        &#34;&#34;&#34;Move forward one batch and return the current FrameBatch object.

        Returns:
            A FrameBatch object that contains the next set of frames.
        &#34;&#34;&#34;

        if self.finished:
            return

        # shift window over by one bandwidth
        self._img[: self.bsize, :, :, :] = self._img[self.bsize :, :, :, :]

        # fill up the bandwidth; with zeros at and of video input
        if self._continue_read:
            self._fill_bandwidth()
        else:
            self.finished = True
            self._img[self.bsize :, :, :, :] = 0

        # update counters
        frame_start = self.fcount
        self.start = self.end
        self.end = self._video_cap.get(CAP_PROP_POS_MSEC)
        self.fcount = self.fcount + self.bsize

        # get frame names
        fnames = list(range(int(frame_start), int(frame_start + self.bsize)))

        # return batch of frames.
        return FrameBatch(
            img=self._img,
            start=self.start,
            end=self.end,
            finished=self.finished,
            fnames=fnames,
            bnum=(frame_start // self.bsize),
        )

    def get_metadata(self):
        &#34;&#34;&#34;Return metadata in a format to put into a DVTOutput object.&#34;&#34;&#34;
        return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}

    def _metadata(self):
        &#34;&#34;&#34;Fill metadata attribute using metadata from the video source.&#34;&#34;&#34;
        path, bname, filename, file_extension = _expand_path(self.input_path)
        return {
            &#34;type&#34;: &#34;video&#34;,
            &#34;fps&#34;: self._video_cap.get(CAP_PROP_FPS),
            &#34;frames&#34;: int(self._video_cap.get(CAP_PROP_FRAME_COUNT)),
            &#34;height&#34;: int(self._video_cap.get(CAP_PROP_FRAME_HEIGHT)),
            &#34;width&#34;: int(self._video_cap.get(CAP_PROP_FRAME_WIDTH)),
            &#34;input_path&#34;: path,
            &#34;input_bname&#34;: bname,
            &#34;input_filename&#34;: filename,
            &#34;input_file_extension&#34;: file_extension,
        }

    def _fill_bandwidth(self):
        &#34;&#34;&#34;Read in the next set of frames from disk and store results.

        This should not be called directly, but only through the next_batch
        method. Otherwise the internal counters will become inconsistent.
        &#34;&#34;&#34;
        for idx in range(self.bsize):
            self._continue_read, frame = self._video_cap.read()
            if self._continue_read:
                self._img[idx + self.bsize, :, :, :] = frame
            else:
                self._img[idx + self.bsize, :, :, :] = 0</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dvt.video.VideoBatchInput.get_metadata"><code class="name flex">
<span>def <span class="ident">get_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return metadata in a format to put into a DVTOutput object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_metadata(self):
    &#34;&#34;&#34;Return metadata in a format to put into a DVTOutput object.&#34;&#34;&#34;
    return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}</code></pre>
</details>
</dd>
<dt id="dvt.video.VideoBatchInput.next_batch"><code class="name flex">
<span>def <span class="ident">next_batch</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Move forward one batch and return the current FrameBatch object.</p>
<h2 id="returns">Returns</h2>
<p>A FrameBatch object that contains the next set of frames.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def next_batch(self):
    &#34;&#34;&#34;Move forward one batch and return the current FrameBatch object.

    Returns:
        A FrameBatch object that contains the next set of frames.
    &#34;&#34;&#34;

    if self.finished:
        return

    # shift window over by one bandwidth
    self._img[: self.bsize, :, :, :] = self._img[self.bsize :, :, :, :]

    # fill up the bandwidth; with zeros at and of video input
    if self._continue_read:
        self._fill_bandwidth()
    else:
        self.finished = True
        self._img[self.bsize :, :, :, :] = 0

    # update counters
    frame_start = self.fcount
    self.start = self.end
    self.end = self._video_cap.get(CAP_PROP_POS_MSEC)
    self.fcount = self.fcount + self.bsize

    # get frame names
    fnames = list(range(int(frame_start), int(frame_start + self.bsize)))

    # return batch of frames.
    return FrameBatch(
        img=self._img,
        start=self.start,
        end=self.end,
        finished=self.finished,
        fnames=fnames,
        bnum=(frame_start // self.bsize),
    )</code></pre>
</details>
</dd>
<dt id="dvt.video.VideoBatchInput.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Open connection to the video file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
    # start settings to
    self.fcount = 0
    self.finished = False
    self.start = 0
    self.end = 0
    self._video_cap = VideoCapture(self.input_path)
    self.meta = self._metadata()
    self.max_batch = ceil(self.meta[&#34;frames&#34;] / self.bsize)

    self._img = zeros(
        (self.bsize * 2, self.meta[&#34;height&#34;], self.meta[&#34;width&#34;], 3),
        dtype=uint8,
    )
    self._fill_bandwidth()  # fill the buffer with the first batch
    self._continue_read = True  # is there any more input left</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dvt.video.VideoFrameInput"><code class="flex name class">
<span>class <span class="ident">VideoFrameInput</span></span>
<span>(</span><span>input_path)</span>
</code></dt>
<dd>
<div class="desc"><p>An input object for extracting single frames from an input video.</p>
<p>Construct a new input from a video file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the video file. Can be any file readable
by the OpenCV function VideoCapture.</dd>
<dt><strong><code>bsize</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of frames to include in a batch. Defaults to
256.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VideoFrameInput:
    &#34;&#34;&#34;An input object for extracting single frames from an input video.&#34;&#34;&#34;

    def __init__(self, input_path):
        &#34;&#34;&#34;Construct a new input from a video file.

        Args:
            input_path (str): Path to the video file. Can be any file readable
                by the OpenCV function VideoCapture.
            bsize (int): Number of frames to include in a batch. Defaults to
                256.
        &#34;&#34;&#34;
        self.input_path = _expand_path(input_path)[0]
        self.meta = None
        self.fcount = -1
        self.finished = False
        self._video_cap = None
        self.reset()

        super().__init__()

    def reset(self):
        &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
        self.fcount = -1
        self.finished = False

        self._video_cap = VideoCapture(self.input_path)
        self._ftotal = int(self._video_cap.get(CAP_PROP_FRAME_COUNT))
        self.meta = self._metadata()

    def next_frame(self):
        &#34;&#34;&#34;Get the next frame.&#34;&#34;&#34;
        if self.finished:
            return

        # get the next frame and return
        self.fcount = self.fcount + 1
        _, frame = self._video_cap.read()
        self.finished = self._ftotal == (self.fcount + 1)
        return frame

    def get_metadata(self):
        &#34;&#34;&#34;Return metadata in a format to put into DVTOutput&#34;&#34;&#34;
        return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}

    def _metadata(self):
        &#34;&#34;&#34;Fill metadata attribute using metadata from the video source.&#34;&#34;&#34;
        path, bname, filename, file_extension = _expand_path(self.input_path)
        return {
            &#34;type&#34;: &#34;video&#34;,
            &#34;fps&#34;: self._video_cap.get(CAP_PROP_FPS),
            &#34;frames&#34;: int(self._video_cap.get(CAP_PROP_FRAME_COUNT)),
            &#34;height&#34;: int(self._video_cap.get(CAP_PROP_FRAME_HEIGHT)),
            &#34;width&#34;: int(self._video_cap.get(CAP_PROP_FRAME_WIDTH)),
            &#34;input_path&#34;: path,
            &#34;input_bname&#34;: bname,
            &#34;input_filename&#34;: filename,
            &#34;input_file_extension&#34;: file_extension,
        }</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dvt.video.VideoFrameInput.get_metadata"><code class="name flex">
<span>def <span class="ident">get_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return metadata in a format to put into DVTOutput</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_metadata(self):
    &#34;&#34;&#34;Return metadata in a format to put into DVTOutput&#34;&#34;&#34;
    return {&#34;meta&#34;: DataFrame(self.meta, index=[0])}</code></pre>
</details>
</dd>
<dt id="dvt.video.VideoFrameInput.next_frame"><code class="name flex">
<span>def <span class="ident">next_frame</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the next frame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def next_frame(self):
    &#34;&#34;&#34;Get the next frame.&#34;&#34;&#34;
    if self.finished:
        return

    # get the next frame and return
    self.fcount = self.fcount + 1
    _, frame = self._video_cap.read()
    self.finished = self._ftotal == (self.fcount + 1)
    return frame</code></pre>
</details>
</dd>
<dt id="dvt.video.VideoFrameInput.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Open connection to the video file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Open connection to the video file.&#34;&#34;&#34;
    self.fcount = -1
    self.finished = False

    self._video_cap = VideoCapture(self.input_path)
    self._ftotal = int(self._video_cap.get(CAP_PROP_FRAME_COUNT))
    self.meta = self._metadata()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://www.distantviewing.org/">
<img src="https://www.distantviewing.org/img/tv.png" alt="" height="50">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dvt" href="index.html">dvt</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dvt.video.FrameBatch" href="#dvt.video.FrameBatch">FrameBatch</a></code></h4>
<ul class="">
<li><code><a title="dvt.video.FrameBatch.get_batch" href="#dvt.video.FrameBatch.get_batch">get_batch</a></code></li>
<li><code><a title="dvt.video.FrameBatch.get_frame_names" href="#dvt.video.FrameBatch.get_frame_names">get_frame_names</a></code></li>
<li><code><a title="dvt.video.FrameBatch.get_frames" href="#dvt.video.FrameBatch.get_frames">get_frames</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dvt.video.VideoBatchInput" href="#dvt.video.VideoBatchInput">VideoBatchInput</a></code></h4>
<ul class="">
<li><code><a title="dvt.video.VideoBatchInput.get_metadata" href="#dvt.video.VideoBatchInput.get_metadata">get_metadata</a></code></li>
<li><code><a title="dvt.video.VideoBatchInput.next_batch" href="#dvt.video.VideoBatchInput.next_batch">next_batch</a></code></li>
<li><code><a title="dvt.video.VideoBatchInput.reset" href="#dvt.video.VideoBatchInput.reset">reset</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dvt.video.VideoFrameInput" href="#dvt.video.VideoFrameInput">VideoFrameInput</a></code></h4>
<ul class="">
<li><code><a title="dvt.video.VideoFrameInput.get_metadata" href="#dvt.video.VideoFrameInput.get_metadata">get_metadata</a></code></li>
<li><code><a title="dvt.video.VideoFrameInput.next_frame" href="#dvt.video.VideoFrameInput.next_frame">next_frame</a></code></li>
<li><code><a title="dvt.video.VideoFrameInput.reset" href="#dvt.video.VideoFrameInput.reset">reset</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p><span style="color:#ddd">&#21328;</span></p>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>